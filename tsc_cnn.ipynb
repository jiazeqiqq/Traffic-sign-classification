{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_df = pd.read_csv('./dataset/train.csv')\n",
    "test_df = pd.read_csv('./dataset/test.csv')\n",
    "\n",
    "path_prefix = \"./dataset/new_imageset/\"\n",
    "\n",
    "# Original categories\n",
    "original_categories = [3, 5, 7, 11, 16, 17, 26, 28, 35, 43, 54, 55]\n",
    "\n",
    "# Create a mapping from original categories to zero-indexed labels\n",
    "label_mapping = {cat: idx for idx, cat in enumerate(original_categories)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None, label_mapping=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.dataframe.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        original_label = int(self.dataframe.iloc[idx, 1])\n",
    "        label = self.label_mapping[original_label]  # Use the mapped label\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets using the label mapping\n",
    "train_dataset = TrafficSignDataset(train_df, path_prefix, transform=transform, label_mapping=label_mapping)\n",
    "test_dataset = TrafficSignDataset(test_df, path_prefix, transform=transform, label_mapping=label_mapping)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TrafficSignCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2)  \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 1000)\n",
    "        self.fc2 = nn.Linear(1000, len(label_mapping))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(-1, 64 * 32 * 32)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.12536561489105225\n",
      "Epoch 2, Loss: 0.012740697711706161\n",
      "Epoch 3, Loss: 0.014430709183216095\n",
      "Epoch 4, Loss: 6.004097485856619e-06\n",
      "Epoch 5, Loss: 0.005064811557531357\n",
      "Epoch 6, Loss: 0.00012272542517166585\n",
      "Epoch 7, Loss: 7.773381184961181e-06\n",
      "Epoch 8, Loss: 2.145743792425492e-06\n",
      "Epoch 9, Loss: 0.0008070935145951807\n",
      "Epoch 10, Loss: 0.00039699123590253294\n",
      "Epoch 11, Loss: 5.878613956156187e-05\n",
      "Epoch 12, Loss: 2.1349103917600587e-05\n",
      "Epoch 13, Loss: 1.792273178580217e-05\n",
      "Epoch 14, Loss: 8.193747817131225e-06\n",
      "Epoch 15, Loss: 6.860466237412766e-05\n",
      "Epoch 16, Loss: 1.6260974007309414e-05\n",
      "Epoch 17, Loss: 2.729230573095265e-06\n",
      "Epoch 18, Loss: 0.00012153424177085981\n",
      "Epoch 19, Loss: 1.7397189367329702e-05\n",
      "Epoch 20, Loss: 9.128302190219983e-05\n",
      "Epoch 21, Loss: 1.0803786608448718e-05\n",
      "Epoch 22, Loss: 7.089407154126093e-05\n",
      "Epoch 23, Loss: 2.2603737306781113e-05\n",
      "Epoch 24, Loss: 7.985239062691107e-05\n",
      "Epoch 25, Loss: 4.436938252183609e-05\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TrafficSignCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 25\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "torch.save(model.state_dict(), 'traffic_sign_model_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.70457902511079%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Accuracy: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrafficSignCNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=65536, out_features=1000, bias=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=12, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
